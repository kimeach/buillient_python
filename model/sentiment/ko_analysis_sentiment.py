import torch
from transformers import BertForSequenceClassification, AutoTokenizer
from sentence_transformers import SentenceTransformer
from keybert import KeyBERT
import re
import json
from dataclasses import dataclass
from typing import List, Dict, Tuple
from datetime import datetime

# CUDA ë””ë²„ê¹… í™˜ê²½ë³€ìˆ˜ ì„¤ì •
import os
os.environ['CUDA_LAUNCH_BLOCKING'] = '1'

# GPU ë©”ëª¨ë¦¬ ì •ë¦¬
torch.cuda.empty_cache()

@dataclass
class StockRecommendation:
    """ì£¼ì‹ ì¶”ì²œ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    symbol: str
    name: str
    sector: str
    sentiment_score: float
    confidence: float
    reasoning: str
    risk_level: str

# === ì£¼ì‹ ì¢…ëª© ë°ì´í„°ë² ì´ìŠ¤ ===
STOCK_DATABASE = {
    # ê¸°ìˆ /IT ì„¹í„°
    "tech": {
        "ì‚¼ì„±ì „ì": {"symbol": "005930", "keywords": ["ë°˜ë„ì²´", "ìŠ¤ë§ˆíŠ¸í°", "ì „ì", "ë©”ëª¨ë¦¬", "ë””ìŠ¤í”Œë ˆì´", "AI", "5G"]},
        "SKí•˜ì´ë‹‰ìŠ¤": {"symbol": "000660", "keywords": ["ë°˜ë„ì²´", "ë©”ëª¨ë¦¬", "DRAM", "ë‚¸ë“œí”Œë˜ì‹œ", "AI", "ë°ì´í„°ì„¼í„°"]},
        "ë„¤ì´ë²„": {"symbol": "035420", "keywords": ["ì¸í„°ë„·", "ê²€ìƒ‰", "í´ë¼ìš°ë“œ", "AI", "í•€í…Œí¬", "ì»¤ë¨¸ìŠ¤"]},
        "ì¹´ì¹´ì˜¤": {"symbol": "035720", "keywords": ["ë©”ì‹ ì €", "í•€í…Œí¬", "ê²Œì„", "ì½˜í…ì¸ ", "ëª¨ë¹Œë¦¬í‹°"]},
        "LGì „ì": {"symbol": "066570", "keywords": ["ê°€ì „", "ìŠ¤ë§ˆíŠ¸í™ˆ", "ì „ê¸°ì°¨", "ë°°í„°ë¦¬", "ë””ìŠ¤í”Œë ˆì´"]},
    },
    # ê¸ˆìœµ ì„¹í„°
    "finance": {
        "KBê¸ˆìœµ": {"symbol": "105560", "keywords": ["ì€í–‰", "ê¸ˆìœµ", "ëŒ€ì¶œ", "ê¸ˆë¦¬", "í•€í…Œí¬", "ë””ì§€í„¸ë±…í‚¹"]},
        "ì‹ í•œì§€ì£¼": {"symbol": "055550", "keywords": ["ì€í–‰", "ê¸ˆìœµ", "ëŒ€ì¶œ", "ê¸ˆë¦¬", "ë³´í—˜"]},
        "í•˜ë‚˜ê¸ˆìœµì§€ì£¼": {"symbol": "086790", "keywords": ["ì€í–‰", "ê¸ˆìœµ", "ëŒ€ì¶œ", "ì¹´ë“œ", "ë³´í—˜"]},
    },
    # ë°”ì´ì˜¤/ì œì•½ ì„¹í„°
    "bio": {
        "ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤": {"symbol": "207940", "keywords": ["ë°”ì´ì˜¤", "ì˜ì•½í’ˆ", "ë°±ì‹ ", "ì¹˜ë£Œì œ", "ì œì•½"]},
        "ì…€íŠ¸ë¦¬ì˜¨": {"symbol": "068270", "keywords": ["ë°”ì´ì˜¤", "í•­ì²´", "ì¹˜ë£Œì œ", "ì˜ì•½í’ˆ", "ë°”ì´ì˜¤ì‹œë°€ëŸ¬"]},
        "ìœ í•œì–‘í–‰": {"symbol": "000100", "keywords": ["ì œì•½", "ì˜ì•½í’ˆ", "ì¹˜ë£Œì œ", "ê±´ê°•", "ì‹ ì•½"]},
    },
    # ì—ë„ˆì§€/í™”í•™ ì„¹í„°
    "energy": {
        "LGí™”í•™": {"symbol": "051910", "keywords": ["ë°°í„°ë¦¬", "ì „ê¸°ì°¨", "í™”í•™", "ì†Œì¬", "ë¦¬íŠ¬", "ESG"]},
        "POSCOí™€ë”©ìŠ¤": {"symbol": "005490", "keywords": ["ì² ê°•", "ë¦¬íŠ¬", "ë°°í„°ë¦¬ì†Œì¬", "ì¹œí™˜ê²½", "ìˆ˜ì†Œ"]},
        "SKì´ë…¸ë² ì´ì…˜": {"symbol": "096770", "keywords": ["ì„ìœ í™”í•™", "ë°°í„°ë¦¬", "ì „ê¸°ì°¨", "ì¹œí™˜ê²½", "ì†Œì¬"]},
    },
    # ìë™ì°¨ ì„¹í„°
    "auto": {
        "í˜„ëŒ€ì°¨": {"symbol": "005380", "keywords": ["ìë™ì°¨", "ì „ê¸°ì°¨", "ìˆ˜ì†Œì°¨", "ëª¨ë¹Œë¦¬í‹°", "ììœ¨ì£¼í–‰"]},
        "ê¸°ì•„": {"symbol": "000270", "keywords": ["ìë™ì°¨", "ì „ê¸°ì°¨", "ì¹œí™˜ê²½", "ëª¨ë¹Œë¦¬í‹°"]},
    },
    # ê±´ì„¤/ë¶€ë™ì‚° ì„¹í„°
    "construction": {
        "ì‚¼ì„±ë¬¼ì‚°": {"symbol": "028260", "keywords": ["ê±´ì„¤", "ë¶€ë™ì‚°", "ì¸í”„ë¼", "í”ŒëœíŠ¸", "ê°œë°œ"]},
        "í˜„ëŒ€ê±´ì„¤": {"symbol": "000720", "keywords": ["ê±´ì„¤", "ë¶€ë™ì‚°", "ì¸í”„ë¼", "ì•„íŒŒíŠ¸", "ê°œë°œ"]},
    },
    # ìœ í†µ/ì†Œë¹„ì¬ ì„¹í„°
    "retail": {
        "ë¡¯ë°ì‡¼í•‘": {"symbol": "023530", "keywords": ["ìœ í†µ", "ë°±í™”ì ", "ë§ˆíŠ¸", "ì†Œë¹„", "ë¦¬í…Œì¼"]},
        "ì‹ ì„¸ê³„": {"symbol": "004170", "keywords": ["ë°±í™”ì ", "ìœ í†µ", "ì´ì»¤ë¨¸ìŠ¤", "ì†Œë¹„", "ë¦¬í…Œì¼"]},
    },
    # ì—”í„°í…Œì¸ë¨¼íŠ¸ ì„¹í„°
    "entertainment": {
        "HYBE": {"symbol": "352820", "keywords": ["ì—”í„°í…Œì¸ë¨¼íŠ¸", "K-POP", "ìŒì•…", "ì½˜í…ì¸ ", "ì•„í‹°ìŠ¤íŠ¸"]},
        "SMì—”í„°í…Œì¸ë¨¼íŠ¸": {"symbol": "041510", "keywords": ["ì—”í„°í…Œì¸ë¨¼íŠ¸", "K-POP", "ìŒì•…", "ì•„í‹°ìŠ¤íŠ¸"]},
    }
}

# === ê¸°ì¡´ ê°ì„± ë¶„ì„ ì½”ë“œ (ê°„ì†Œí™”) ===
print("ê°ì„± ë¶„ì„ ëª¨ë¸ ë¡œë”© ì¤‘...")
sentiment_model_name = "monologg/kobert"
sentiment_tokenizer = AutoTokenizer.from_pretrained(sentiment_model_name, trust_remote_code=True, use_fast=False)
sentiment_model = BertForSequenceClassification.from_pretrained(sentiment_model_name, num_labels=3)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
sentiment_model = sentiment_model.to(device)

print("í‚¤ì›Œë“œ ì¶”ì¶œ ëª¨ë¸ ë¡œë”© ì¤‘...")
try:
    kw_model = KeyBERT(model=SentenceTransformer("jhgan/ko-sroberta-multitask"))
except:
    kw_model = KeyBERT(model=SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2"))

def predict_sentiment(text):
    try:
        sentiment_model.eval()
        text = re.sub(r'[^\w\sê°€-í£]', ' ', text).strip()
        
        if not text:
            return {"ì˜ˆì¸¡": "ì¤‘ë¦½", "ì‹ ë¢°ë„": 0.5, "ì ìˆ˜": 0.0}
        
        inputs = sentiment_tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=128)
        inputs = {k: v.to(device) for k, v in inputs.items()}
        
        with torch.no_grad():
            outputs = sentiment_model(**inputs)
            probs = torch.nn.functional.softmax(outputs.logits, dim=-1)
            pred = torch.argmax(probs, dim=1).item()
            confidence = torch.max(probs).item()
            
        label_map = {0: "ë¶€ì •", 1: "ì¤‘ë¦½", 2: "ê¸ì •"}
        # ê°ì„± ì ìˆ˜ ê³„ì‚° (-1 ~ 1)
        sentiment_score = (probs[0][2].item() - probs[0][0].item())
        
        return {
            "ì˜ˆì¸¡": label_map[pred],
            "ì‹ ë¢°ë„": confidence,
            "ì ìˆ˜": sentiment_score
        }
    except Exception as e:
        return {"ì˜ˆì¸¡": "ì¤‘ë¦½", "ì‹ ë¢°ë„": 0.5, "ì ìˆ˜": 0.0}

def extract_keywords(text, top_n=10):
    try:
        text = re.sub(r'[^\w\sê°€-í£]', ' ', text).strip()
        if len(text) < 10:
            return text.split()
        
        keywords = kw_model.extract_keywords(
            text, top_n=top_n, 
            stop_words=["ìˆë‹¤", "í–ˆë‹¤", "ëŒ€í•œ", "ë“±", "ì´ë‹¤", "í•˜ë‹¤", "ë˜ë‹¤", "ê²ƒ", "ìˆ˜", "ë•Œ", "ë…„", "ì›”", "ì¼"],
            use_mmr=True, diversity=0.5
        )
        return [kw for kw, score in keywords]
    except:
        return text.split()[:top_n]

# === ì£¼ì‹ ì¶”ì²œ ì‹œìŠ¤í…œ ===
class StockRecommendationEngine:
    def __init__(self):
        self.stock_db = STOCK_DATABASE
        
    def calculate_keyword_match_score(self, news_keywords: List[str], stock_keywords: List[str]) -> float:
        """ë‰´ìŠ¤ í‚¤ì›Œë“œì™€ ì£¼ì‹ í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°"""
        if not news_keywords or not stock_keywords:
            return 0.0
            
        matches = 0
        total_checks = 0
        
        for news_kw in news_keywords:
            for stock_kw in stock_keywords:
                total_checks += 1
                # í‚¤ì›Œë“œ í¬í•¨ ê´€ê³„ í™•ì¸
                if news_kw in stock_kw or stock_kw in news_kw:
                    matches += 1
                # ë¶€ë¶„ ë§¤ì¹­ (2ê¸€ì ì´ìƒ)
                elif len(news_kw) >= 2 and len(stock_kw) >= 2:
                    if news_kw[:2] == stock_kw[:2]:
                        matches += 0.5
        
        return matches / max(total_checks, 1) if total_checks > 0 else 0.0
    
    def determine_risk_level(self, sentiment_score: float, confidence: float) -> str:
        """ë¦¬ìŠ¤í¬ ë ˆë²¨ ê²°ì •"""
        if confidence < 0.6:
            return "ë†’ìŒ"
        elif sentiment_score > 0.3 and confidence > 0.8:
            return "ë‚®ìŒ"
        elif sentiment_score > 0.1:
            return "ì¤‘ê°„"
        else:
            return "ë†’ìŒ"
    
    def recommend_stocks(self, news_text: str, top_n: int = 5) -> List[StockRecommendation]:
        """ë‰´ìŠ¤ ê¸°ë°˜ ì£¼ì‹ ì¶”ì²œ"""
        # 1. ë‰´ìŠ¤ ê°ì„± ë¶„ì„
        sentiment_result = predict_sentiment(news_text)
        overall_sentiment = sentiment_result["ì ìˆ˜"]
        overall_confidence = sentiment_result["ì‹ ë¢°ë„"]
        
        # 2. í‚¤ì›Œë“œ ì¶”ì¶œ
        news_keywords = extract_keywords(news_text)
        
        # 3. ê° ì£¼ì‹ì— ëŒ€í•´ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
        recommendations = []
        
        for sector, stocks in self.stock_db.items():
            for stock_name, stock_info in stocks.items():
                # í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜
                keyword_match_score = self.calculate_keyword_match_score(
                    news_keywords, stock_info["keywords"]
                )
                
                # í‚¤ì›Œë“œê°€ ë§¤ì¹­ë˜ì§€ ì•Šìœ¼ë©´ ìŠ¤í‚µ
                if keyword_match_score < 0.1:
                    continue
                
                # ê° í‚¤ì›Œë“œë³„ ê°ì„± ë¶„ì„
                keyword_sentiments = []
                for keyword in news_keywords:
                    if any(kw in keyword or keyword in kw for kw in stock_info["keywords"]):
                        kw_sentiment = predict_sentiment(keyword)
                        keyword_sentiments.append(kw_sentiment["ì ìˆ˜"])
                
                # ìµœì¢… ê°ì„± ì ìˆ˜ (ì „ì²´ ê°ì„± + í‚¤ì›Œë“œ ê°ì„± í‰ê· )
                if keyword_sentiments:
                    keyword_avg_sentiment = sum(keyword_sentiments) / len(keyword_sentiments)
                    final_sentiment_score = (overall_sentiment * 0.6 + keyword_avg_sentiment * 0.4)
                else:
                    final_sentiment_score = overall_sentiment
                
                # ìµœì¢… ì¶”ì²œ ì ìˆ˜ (ê°ì„± ì ìˆ˜ * í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ * ì‹ ë¢°ë„)
                final_score = abs(final_sentiment_score) * keyword_match_score * overall_confidence
                
                # ì¶”ì²œ ì‚¬ìœ  ìƒì„±
                matched_keywords = [kw for kw in news_keywords 
                                  if any(stock_kw in kw or kw in stock_kw for stock_kw in stock_info["keywords"])]
                
                reasoning = f"ë§¤ì¹­ í‚¤ì›Œë“œ: {', '.join(matched_keywords[:3])} | "
                reasoning += f"ê°ì„±: {sentiment_result['ì˜ˆì¸¡']} | "
                reasoning += f"ì„¹í„°: {sector}"
                
                # ë¦¬ìŠ¤í¬ ë ˆë²¨ ê²°ì •
                risk_level = self.determine_risk_level(final_sentiment_score, overall_confidence)
                
                recommendation = StockRecommendation(
                    symbol=stock_info["symbol"],
                    name=stock_name,
                    sector=sector,
                    sentiment_score=final_sentiment_score,
                    confidence=final_score,
                    reasoning=reasoning,
                    risk_level=risk_level
                )
                
                recommendations.append(recommendation)
        
        # ì‹ ë¢°ë„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ Nê°œ ë°˜í™˜
        recommendations.sort(key=lambda x: x.confidence, reverse=True)
        return recommendations[:top_n]

# === ë¶„ì„ ë° ì¶”ì²œ í†µí•© ì‹œìŠ¤í…œ ===
def analyze_news_and_recommend_stocks(news_text: str, top_n: int = 5):
    """ë‰´ìŠ¤ ë¶„ì„ + ì£¼ì‹ ì¶”ì²œ í†µí•© í•¨ìˆ˜"""
    print("=" * 60)
    print("ğŸ“° ë‰´ìŠ¤ ê°ì„± ë¶„ì„ ë° ì£¼ì‹ ì¶”ì²œ ì‹œìŠ¤í…œ")
    print("=" * 60)
    print(f"ğŸ“° ì…ë ¥ ë‰´ìŠ¤: {news_text}\n")
    
    # 1. ê¸°ë³¸ ê°ì„± ë¶„ì„
    print("ğŸ“Š ì „ì²´ ë‰´ìŠ¤ ê°ì„± ë¶„ì„:")
    overall_sentiment = predict_sentiment(news_text)
    print(f"ì „ì²´ ê°ì„±: {overall_sentiment['ì˜ˆì¸¡']} (ì‹ ë¢°ë„: {overall_sentiment['ì‹ ë¢°ë„']:.4f})")
    print(f"ê°ì„± ì ìˆ˜: {overall_sentiment['ì ìˆ˜']:.4f} (-1: ë§¤ìš°ë¶€ì •, 0: ì¤‘ë¦½, +1: ë§¤ìš°ê¸ì •)")
    print()
    
    # 2. í‚¤ì›Œë“œ ì¶”ì¶œ
    print("ğŸ”‘ ì¶”ì¶œëœ í‚¤ì›Œë“œ:")
    keywords = extract_keywords(news_text)
    print(", ".join(keywords))
    print()
    
    # 3. ì£¼ì‹ ì¶”ì²œ
    print("ğŸ“ˆ ì£¼ì‹ ì¢…ëª© ì¶”ì²œ:")
    recommender = StockRecommendationEngine()
    recommendations = recommender.recommend_stocks(news_text, top_n)
    
    if not recommendations:
        print("âŒ ê´€ë ¨ ì£¼ì‹ ì¢…ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ìƒìœ„ {len(recommendations)}ê°œ ì¶”ì²œ ì¢…ëª©:")
    print("-" * 80)
    
    for i, rec in enumerate(recommendations, 1):
        print(f"{i}. {rec.name} ({rec.symbol})")
        print(f"   ğŸ“ ì„¹í„°: {rec.sector}")
        print(f"   ğŸ“Š ê°ì„±ì ìˆ˜: {rec.sentiment_score:.4f}")
        print(f"   ğŸ¯ ì‹ ë¢°ë„: {rec.confidence:.4f}")
        print(f"   âš ï¸  ë¦¬ìŠ¤í¬: {rec.risk_level}")
        print(f"   ğŸ’­ ì¶”ì²œì‚¬ìœ : {rec.reasoning}")
        print("-" * 80)

# === í…ŒìŠ¤íŠ¸ ë° ì‹¤í–‰ ===
def test_stock_recommendation():
    """ë‹¤ì–‘í•œ ë‰´ìŠ¤ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸"""
    test_cases = [
        {
            "title": "ê¸ì •ì  ê¸°ìˆ  ë‰´ìŠ¤",
            "news": "ì‚¼ì„±ì „ìê°€ ìƒˆë¡œìš´ AI ë°˜ë„ì²´ ê¸°ìˆ ì„ ê°œë°œí•˜ì—¬ ë©”ëª¨ë¦¬ ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë˜ì—ˆë‹¤. 5Gì™€ ë°ì´í„°ì„¼í„° ì‹œì¥ì—ì„œì˜ ê²½ìŸë ¥ì´ ê°•í™”ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤."
        },
        {
            "title": "ë¶€ì •ì  ê¸ˆìœµ ë‰´ìŠ¤", 
            "news": "ê¸ˆë¦¬ ì¸ìƒê³¼ ëŒ€ì¶œ ê·œì œ ê°•í™”ë¡œ ì€í–‰ë“¤ì˜ ìˆ˜ìµì„±ì´ ì•…í™”ë˜ê³  ìˆë‹¤. KBê¸ˆìœµê³¼ ì‹ í•œì§€ì£¼ ë“± ì£¼ìš” ê¸ˆìœµì§€ì£¼ì˜ ì‹¤ì  ë¶€ì§„ì´ ìš°ë ¤ëœë‹¤."
        },
        {
            "title": "ê¸ì •ì  ë°”ì´ì˜¤ ë‰´ìŠ¤",
            "news": "ì…€íŠ¸ë¦¬ì˜¨ì˜ ìƒˆë¡œìš´ í•­ì²´ ì¹˜ë£Œì œê°€ ì„ìƒ 3ìƒì—ì„œ ë›°ì–´ë‚œ íš¨ê³¼ë¥¼ ë³´ì˜€ë‹¤. ë°”ì´ì˜¤ì‹œë°€ëŸ¬ ì‹œì¥ì—ì„œì˜ ê²½ìŸë ¥ì´ ë”ìš± ê°•í™”ë  ì „ë§ì´ë‹¤."
        },
        {
            "title": "ì „ê¸°ì°¨ ê´€ë ¨ ë‰´ìŠ¤",
            "news": "í˜„ëŒ€ì°¨ê·¸ë£¹ì´ ì „ê¸°ì°¨ ìƒì‚°ì„ í™•ëŒ€í•˜ê³  ë°°í„°ë¦¬ ê¸°ìˆ  ê°œë°œì— ëŒ€ê·œëª¨ íˆ¬ìë¥¼ ë°œí‘œí–ˆë‹¤. LGí™”í•™ê³¼ì˜ í˜‘ë ¥ë„ ê°•í™”ë  ì˜ˆì •ì´ë‹¤."
        },
        {
            "title": "ë¶€ë™ì‚° ì •ì±… ë‰´ìŠ¤",
            "news": "ì •ë¶€ì˜ ë¶€ë™ì‚° ê·œì œ ì™„í™” ì •ì±…ìœ¼ë¡œ ê±´ì„¤ì—…ê³„ì— í˜¸ì¬ê°€ ì˜ˆìƒëœë‹¤. ì‚¼ì„±ë¬¼ì‚°ê³¼ í˜„ëŒ€ê±´ì„¤ ë“± ëŒ€í˜• ê±´ì„¤ì‚¬ë“¤ì˜ ìˆ˜ì£¼ ì¦ê°€ê°€ ê¸°ëŒ€ëœë‹¤."
        }
    ]
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nğŸ§ª í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ {i}: {test_case['title']}")
        try:
            analyze_news_and_recommend_stocks(test_case['news'], top_n=3)
        except Exception as e:
            print(f"âŒ í…ŒìŠ¤íŠ¸ {i} ì‹¤íŒ¨: {e}")
        
        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        print("\n" + "="*100)

if __name__ == "__main__":
    print("ğŸš€ ê°ì„± ë¶„ì„ ê¸°ë°˜ ì£¼ì‹ ì¶”ì²œ ì‹œìŠ¤í…œ ì‹œì‘")
    test_stock_recommendation()