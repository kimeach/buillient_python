import torch
from transformers import BertForSequenceClassification, AutoTokenizer
from sentence_transformers import SentenceTransformer
from keybert import KeyBERT
import re
import json
from dataclasses import dataclass
from typing import List, Dict, Tuple
from datetime import datetime
import numpy as np

# CUDA ë””ë²„ê¹… í™˜ê²½ë³€ìˆ˜ ì„¤ì •
import os
os.environ['CUDA_LAUNCH_BLOCKING'] = '1'

# GPU ë©”ëª¨ë¦¬ ì •ë¦¬
torch.cuda.empty_cache()

@dataclass
class StockRecommendation:
    """ì£¼ì‹ ì¶”ì²œ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    symbol: str
    name: str
    sector: str
    sentiment_score: float
    confidence: float
    reasoning: str
    risk_level: str

# === ì£¼ì‹ ì¢…ëª© ë°ì´í„°ë² ì´ìŠ¤ ===
STOCK_DATABASE = {
    # ê¸°ìˆ /IT ì„¹í„°
    "tech": {
        "ì‚¼ì„±ì „ì": {"symbol": "005930", "keywords": ["ë°˜ë„ì²´", "ìŠ¤ë§ˆíŠ¸í°", "ì „ì", "ë©”ëª¨ë¦¬", "ë””ìŠ¤í”Œë ˆì´", "AI", "5G"]},
        "SKí•˜ì´ë‹‰ìŠ¤": {"symbol": "000660", "keywords": ["ë°˜ë„ì²´", "ë©”ëª¨ë¦¬", "DRAM", "ë‚¸ë“œí”Œë˜ì‹œ", "AI", "ë°ì´í„°ì„¼í„°"]},
        "ë„¤ì´ë²„": {"symbol": "035420", "keywords": ["ì¸í„°ë„·", "ê²€ìƒ‰", "í´ë¼ìš°ë“œ", "AI", "í•€í…Œí¬", "ì»¤ë¨¸ìŠ¤"]},
        "ì¹´ì¹´ì˜¤": {"symbol": "035720", "keywords": ["ë©”ì‹ ì €", "í•€í…Œí¬", "ê²Œì„", "ì½˜í…ì¸ ", "ëª¨ë¹Œë¦¬í‹°"]},
        "LGì „ì": {"symbol": "066570", "keywords": ["ê°€ì „", "ìŠ¤ë§ˆíŠ¸í™ˆ", "ì „ê¸°ì°¨", "ë°°í„°ë¦¬", "ë””ìŠ¤í”Œë ˆì´"]},
    },
    # ê¸ˆìœµ ì„¹í„°
    "finance": {
        "KBê¸ˆìœµ": {"symbol": "105560", "keywords": ["ì€í–‰", "ê¸ˆìœµ", "ëŒ€ì¶œ", "ê¸ˆë¦¬", "í•€í…Œí¬", "ë””ì§€í„¸ë±…í‚¹"]},
        "ì‹ í•œì§€ì£¼": {"symbol": "055550", "keywords": ["ì€í–‰", "ê¸ˆìœµ", "ëŒ€ì¶œ", "ê¸ˆë¦¬", "ë³´í—˜"]},
        "í•˜ë‚˜ê¸ˆìœµì§€ì£¼": {"symbol": "086790", "keywords": ["ì€í–‰", "ê¸ˆìœµ", "ëŒ€ì¶œ", "ì¹´ë“œ", "ë³´í—˜"]},
    },
    # ë°”ì´ì˜¤/ì œì•½ ì„¹í„°
    "bio": {
        "ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤": {"symbol": "207940", "keywords": ["ë°”ì´ì˜¤", "ì˜ì•½í’ˆ", "ë°±ì‹ ", "ì¹˜ë£Œì œ", "ì œì•½"]},
        "ì…€íŠ¸ë¦¬ì˜¨": {"symbol": "068270", "keywords": ["ë°”ì´ì˜¤", "í•­ì²´", "ì¹˜ë£Œì œ", "ì˜ì•½í’ˆ", "ë°”ì´ì˜¤ì‹œë°€ëŸ¬"]},
        "ìœ í•œì–‘í–‰": {"symbol": "000100", "keywords": ["ì œì•½", "ì˜ì•½í’ˆ", "ì¹˜ë£Œì œ", "ê±´ê°•", "ì‹ ì•½"]},
    },
    # ì—ë„ˆì§€/í™”í•™ ì„¹í„°
    "energy": {
        "LGí™”í•™": {"symbol": "051910", "keywords": ["ë°°í„°ë¦¬", "ì „ê¸°ì°¨", "í™”í•™", "ì†Œì¬", "ë¦¬íŠ¬", "ESG"]},
        "POSCOí™€ë”©ìŠ¤": {"symbol": "005490", "keywords": ["ì² ê°•", "ë¦¬íŠ¬", "ë°°í„°ë¦¬ì†Œì¬", "ì¹œí™˜ê²½", "ìˆ˜ì†Œ"]},
        "SKì´ë…¸ë² ì´ì…˜": {"symbol": "096770", "keywords": ["ì„ìœ í™”í•™", "ë°°í„°ë¦¬", "ì „ê¸°ì°¨", "ì¹œí™˜ê²½", "ì†Œì¬"]},
    },
    # ìë™ì°¨ ì„¹í„°
    "auto": {
        "í˜„ëŒ€ì°¨": {"symbol": "005380", "keywords": ["ìë™ì°¨", "ì „ê¸°ì°¨", "ìˆ˜ì†Œì°¨", "ëª¨ë¹Œë¦¬í‹°", "ììœ¨ì£¼í–‰"]},
        "ê¸°ì•„": {"symbol": "000270", "keywords": ["ìë™ì°¨", "ì „ê¸°ì°¨", "ì¹œí™˜ê²½", "ëª¨ë¹Œë¦¬í‹°"]},
    },
    # ê±´ì„¤/ë¶€ë™ì‚° ì„¹í„°
    "construction": {
        "ì‚¼ì„±ë¬¼ì‚°": {"symbol": "028260", "keywords": ["ê±´ì„¤", "ë¶€ë™ì‚°", "ì¸í”„ë¼", "í”ŒëœíŠ¸", "ê°œë°œ"]},
        "í˜„ëŒ€ê±´ì„¤": {"symbol": "000720", "keywords": ["ê±´ì„¤", "ë¶€ë™ì‚°", "ì¸í”„ë¼", "ì•„íŒŒíŠ¸", "ê°œë°œ"]},
    },
    # ìœ í†µ/ì†Œë¹„ì¬ ì„¹í„°
    "retail": {
        "ë¡¯ë°ì‡¼í•‘": {"symbol": "023530", "keywords": ["ìœ í†µ", "ë°±í™”ì ", "ë§ˆíŠ¸", "ì†Œë¹„", "ë¦¬í…Œì¼"]},
        "ì‹ ì„¸ê³„": {"symbol": "004170", "keywords": ["ë°±í™”ì ", "ìœ í†µ", "ì´ì»¤ë¨¸ìŠ¤", "ì†Œë¹„", "ë¦¬í…Œì¼"]},
    },
    # ì—”í„°í…Œì¸ë¨¼íŠ¸ ì„¹í„°
    "entertainment": {
        "HYBE": {"symbol": "352820", "keywords": ["ì—”í„°í…Œì¸ë¨¼íŠ¸", "K-POP", "ìŒì•…", "ì½˜í…ì¸ ", "ì•„í‹°ìŠ¤íŠ¸"]},
        "SMì—”í„°í…Œì¸ë¨¼íŠ¸": {"symbol": "041510", "keywords": ["ì—”í„°í…Œì¸ë¨¼íŠ¸", "K-POP", "ìŒì•…", "ì•„í‹°ìŠ¤íŠ¸"]},
    }
}

# === KR-FinBert-SC ê°ì„± ë¶„ì„ ëª¨ë¸ ë¡œë”© ===
print("KR-FinBert-SC ê°ì„± ë¶„ì„ ëª¨ë¸ ë¡œë”© ì¤‘...")
sentiment_model_name = "snunlp/KR-FinBert-SC"
try:
    sentiment_tokenizer = AutoTokenizer.from_pretrained(sentiment_model_name)
    sentiment_model = BertForSequenceClassification.from_pretrained(sentiment_model_name)
    print("âœ… KR-FinBert-SC ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
except Exception as e:
    print(f"âŒ KR-FinBert-SC ë¡œë”© ì‹¤íŒ¨: {e}")
    print("ğŸ”„ ê¸°ë³¸ KoBert ëª¨ë¸ë¡œ ëŒ€ì²´...")
    sentiment_model_name = "monologg/kobert"
    sentiment_tokenizer = AutoTokenizer.from_pretrained(sentiment_model_name, trust_remote_code=True, use_fast=False)
    sentiment_model = BertForSequenceClassification.from_pretrained(sentiment_model_name, num_labels=3)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
sentiment_model = sentiment_model.to(device)

print("í‚¤ì›Œë“œ ì¶”ì¶œ ëª¨ë¸ ë¡œë”© ì¤‘...")
try:
    kw_model = KeyBERT(model=SentenceTransformer("jhgan/ko-sroberta-multitask"))
    print("âœ… í•œêµ­ì–´ í‚¤ì›Œë“œ ì¶”ì¶œ ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
except:
    print("ğŸ”„ ë‹¤êµ­ì–´ í‚¤ì›Œë“œ ì¶”ì¶œ ëª¨ë¸ë¡œ ëŒ€ì²´...")
    kw_model = KeyBERT(model=SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2"))

def predict_sentiment(text):
    """KR-FinBert-SCë¥¼ ì‚¬ìš©í•œ ê¸ˆìœµ ë„ë©”ì¸ ê°ì„± ë¶„ì„"""
    try:
        sentiment_model.eval()
        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (ê¸ˆìœµ ë„ë©”ì¸ì— ë§ê²Œ ì¡°ì •)
        text = re.sub(r'[^\w\sê°€-í£%]', ' ', text).strip()
        
        if not text:
            return {"ì˜ˆì¸¡": "ì¤‘ë¦½", "ì‹ ë¢°ë„": 0.5, "ì ìˆ˜": 0.0}
        
        # KR-FinBert-SCëŠ” ì¼ë°˜ì ìœ¼ë¡œ ë” ê¸´ í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆìŒ
        max_length = 256 if "KR-FinBert" in sentiment_model_name else 128
        
        inputs = sentiment_tokenizer(
            text, 
            return_tensors="pt", 
            truncation=True, 
            padding=True, 
            max_length=max_length
        )
        inputs = {k: v.to(device) for k, v in inputs.items()}
        
        with torch.no_grad():
            outputs = sentiment_model(**inputs)
            probs = torch.nn.functional.softmax(outputs.logits, dim=-1)
            pred = torch.argmax(probs, dim=1).item()
            confidence = torch.max(probs).item()
            
        # KR-FinBert-SCì˜ ë¼ë²¨ ë§¤í•‘ (ì¼ë°˜ì ìœ¼ë¡œ 0: ë¶€ì •, 1: ì¤‘ë¦½, 2: ê¸ì •)
        if "KR-FinBert" in sentiment_model_name:
            # ê¸ˆìœµ ë„ë©”ì¸ íŠ¹í™” ë¼ë²¨ ë§¤í•‘
            label_map = {0: "ë¶€ì •", 1: "ì¤‘ë¦½", 2: "ê¸ì •"}
            # ê¸ˆìœµ ë„ë©”ì¸ì—ì„œëŠ” ë” ì„¬ì„¸í•œ ê°ì„± ì ìˆ˜ ê³„ì‚°
            sentiment_score = (probs[0][2].item() - probs[0][0].item()) * 1.2  # ê¸ˆìœµ ë„ë©”ì¸ ê°€ì¤‘ì¹˜
            # ë²”ìœ„ë¥¼ -1 ~ 1ë¡œ ì œí•œ
            sentiment_score = max(-1.0, min(1.0, sentiment_score))
        else:
            # ê¸°ë³¸ KoBert ë¼ë²¨ ë§¤í•‘
            label_map = {0: "ë¶€ì •", 1: "ì¤‘ë¦½", 2: "ê¸ì •"}
            sentiment_score = (probs[0][2].item() - probs[0][0].item())
        
        return {
            "ì˜ˆì¸¡": label_map[pred],
            "ì‹ ë¢°ë„": confidence,
            "ì ìˆ˜": sentiment_score,
            "ëª¨ë¸": sentiment_model_name.split("/")[-1],  # ì‚¬ìš©ëœ ëª¨ë¸ ì •ë³´
            "ìƒì„¸í™•ë¥ ": {
                "ë¶€ì •": float(probs[0][0]),
                "ì¤‘ë¦½": float(probs[0][1]), 
                "ê¸ì •": float(probs[0][2])
            }
        }
    except Exception as e:
        print(f"ê°ì„± ë¶„ì„ ì˜¤ë¥˜: {e}")
        return {"ì˜ˆì¸¡": "ì¤‘ë¦½", "ì‹ ë¢°ë„": 0.5, "ì ìˆ˜": 0.0, "ëª¨ë¸": "error"}

def extract_keywords(text, top_n=10):
    """ê¸ˆìœµ ë„ë©”ì¸ì— íŠ¹í™”ëœ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    try:
        # ê¸ˆìœµ ë„ë©”ì¸ íŠ¹í™” ì „ì²˜ë¦¬
        text = re.sub(r'[^\w\sê°€-í£%]', ' ', text).strip()
        if len(text) < 10:
            return text.split()
        
        # ê¸ˆìœµ ë„ë©”ì¸ ë¶ˆìš©ì–´ í™•ì¥
        financial_stopwords = [
            "ìˆë‹¤", "í–ˆë‹¤", "ëŒ€í•œ", "ë“±", "ì´ë‹¤", "í•˜ë‹¤", "ë˜ë‹¤", "ê²ƒ", "ìˆ˜", "ë•Œ", 
            "ë…„", "ì›”", "ì¼", "ì›", "ë‹¬ëŸ¬", "ì–µ", "ì¡°", "ë§Œ", "ê°œ", "ëª…", "í†µí•´",
            "ê´€ë ¨", "ê²½ìš°", "ë•Œë¬¸", "ìœ„í•´", "ë”°ë¼", "ìœ„í•œ", "ì´ë²ˆ", "ì§€ë‚œ", "ì˜¬í•´",
            "ë‚´ë…„", "ìµœê·¼", "í˜„ì¬", "ì˜¤ëŠ˜", "ì–´ì œ", "ë‚´ì¼"
        ]
        
        keywords = kw_model.extract_keywords(
            text, 
            top_n=top_n, 
            stop_words=financial_stopwords,
            use_mmr=True, 
            diversity=0.7  # ê¸ˆìœµ ë„ë©”ì¸ì—ì„œëŠ” ë‹¤ì–‘ì„±ì„ ë†’ì—¬ ë” í¬ê´„ì ì¸ í‚¤ì›Œë“œ ì¶”ì¶œ
        )
        return [kw for kw, score in keywords]
    except Exception as e:
        print(f"í‚¤ì›Œë“œ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return text.split()[:top_n]

# === ì£¼ì‹ ì¶”ì²œ ì‹œìŠ¤í…œ (í–¥ìƒëœ ë²„ì „) ===
class StockRecommendationEngine:
    def __init__(self):
        self.stock_db = STOCK_DATABASE
        
    def calculate_keyword_match_score(self, news_keywords: List[str], stock_keywords: List[str]) -> float:
        """í–¥ìƒëœ í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°"""
        if not news_keywords or not stock_keywords:
            return 0.0
            
        matches = 0
        total_weight = 0
        
        for news_kw in news_keywords:
            for stock_kw in stock_keywords:
                # ê°€ì¤‘ì¹˜ ê³„ì‚° (í‚¤ì›Œë“œ ê¸¸ì´ ê¸°ë°˜)
                weight = min(len(news_kw), len(stock_kw)) / 10
                total_weight += weight
                
                # ì™„ì „ ì¼ì¹˜
                if news_kw == stock_kw:
                    matches += weight * 1.0
                # í¬í•¨ ê´€ê³„
                elif news_kw in stock_kw or stock_kw in news_kw:
                    matches += weight * 0.8
                # ë¶€ë¶„ ë§¤ì¹­ (2ê¸€ì ì´ìƒ)
                elif len(news_kw) >= 2 and len(stock_kw) >= 2:
                    if news_kw[:2] == stock_kw[:2]:
                        matches += weight * 0.5
        
        return matches / max(total_weight, 1) if total_weight > 0 else 0.0
    
    def determine_risk_level(self, sentiment_score: float, confidence: float, keyword_match: float) -> str:
        """ê°œì„ ëœ ë¦¬ìŠ¤í¬ ë ˆë²¨ ê²°ì •"""
        # ì—¬ëŸ¬ ìš”ì†Œë¥¼ ì¢…í•©í•œ ë¦¬ìŠ¤í¬ í‰ê°€
        risk_score = 0
        
        # ì‹ ë¢°ë„ ê¸°ë°˜ ë¦¬ìŠ¤í¬
        if confidence < 0.6:
            risk_score += 2
        elif confidence < 0.8:
            risk_score += 1
        
        # ê°ì„± ì ìˆ˜ ê¸°ë°˜ ë¦¬ìŠ¤í¬
        if abs(sentiment_score) < 0.1:  # ì¤‘ë¦½ì— ê°€ê¹Œì›€
            risk_score += 1
        elif sentiment_score < -0.5:  # ë§¤ìš° ë¶€ì •ì 
            risk_score += 2
        
        # í‚¤ì›Œë“œ ë§¤ì¹­ ê¸°ë°˜ ë¦¬ìŠ¤í¬
        if keyword_match < 0.2:
            risk_score += 2
        elif keyword_match < 0.4:
            risk_score += 1
        
        if risk_score >= 4:
            return "ë†’ìŒ"
        elif risk_score >= 2:
            return "ì¤‘ê°„"
        else:
            return "ë‚®ìŒ"
    
    def recommend_stocks(self, news_text: str, top_n: int = 5) -> List[StockRecommendation]:
        """KR-FinBert-SC ê¸°ë°˜ ì£¼ì‹ ì¶”ì²œ"""
        # 1. ë‰´ìŠ¤ ê°ì„± ë¶„ì„ (KR-FinBert-SC ì‚¬ìš©)
        sentiment_result = predict_sentiment(news_text)
        overall_sentiment = sentiment_result["ì ìˆ˜"]
        overall_confidence = sentiment_result["ì‹ ë¢°ë„"]
        
        print(f"ğŸ“Š ì „ì²´ ê°ì„± ë¶„ì„ ê²°ê³¼:")
        print(f"   ëª¨ë¸: {sentiment_result.get('ëª¨ë¸', 'Unknown')}")
        print(f"   ê°ì„±: {sentiment_result['ì˜ˆì¸¡']} (ì ìˆ˜: {overall_sentiment:.4f})")
        print(f"   ì‹ ë¢°ë„: {overall_confidence:.4f}")
        
        # 2. í‚¤ì›Œë“œ ì¶”ì¶œ
        news_keywords = extract_keywords(news_text, top_n=15)  # ë” ë§ì€ í‚¤ì›Œë“œ ì¶”ì¶œ
        print(f"ğŸ”‘ ì¶”ì¶œëœ í‚¤ì›Œë“œ: {', '.join(news_keywords[:10])}")
        
        # 3. ê° ì£¼ì‹ì— ëŒ€í•´ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
        recommendations = []
        
        for sector, stocks in self.stock_db.items():
            for stock_name, stock_info in stocks.items():
                # í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜
                keyword_match_score = self.calculate_keyword_match_score(
                    news_keywords, stock_info["keywords"]
                )
                
                # í‚¤ì›Œë“œê°€ ë§¤ì¹­ë˜ì§€ ì•Šìœ¼ë©´ ìŠ¤í‚µ
                if keyword_match_score < 0.1:
                    continue
                
                # ê° í‚¤ì›Œë“œë³„ ê°ì„± ë¶„ì„ (ê¸ˆìœµ ë„ë©”ì¸ íŠ¹í™”)
                keyword_sentiments = []
                for keyword in news_keywords:
                    if any(kw in keyword or keyword in kw for kw in stock_info["keywords"]):
                        # í‚¤ì›Œë“œ ë§¥ë½ì„ í¬í•¨í•œ ê°ì„± ë¶„ì„
                        context_text = f"{keyword} ê´€ë ¨ {news_text[:100]}"
                        kw_sentiment = predict_sentiment(context_text)
                        keyword_sentiments.append(kw_sentiment["ì ìˆ˜"])
                
                # ìµœì¢… ê°ì„± ì ìˆ˜ (ì „ì²´ ê°ì„± + í‚¤ì›Œë“œ ê°ì„± ê°€ì¤‘í‰ê· )
                if keyword_sentiments:
                    keyword_avg_sentiment = np.mean(keyword_sentiments)
                    # ê¸ˆìœµ ë„ë©”ì¸ì—ì„œëŠ” í‚¤ì›Œë“œ ê°ì„±ì„ ë” ì¤‘ìš”í•˜ê²Œ ê³ ë ¤
                    final_sentiment_score = (overall_sentiment * 0.4 + keyword_avg_sentiment * 0.6)
                else:
                    final_sentiment_score = overall_sentiment
                
                # ìµœì¢… ì¶”ì²œ ì ìˆ˜ ê³„ì‚° (ê°œì„ ëœ ê³µì‹)
                base_score = abs(final_sentiment_score) * keyword_match_score * overall_confidence
                # ê¸ˆìœµ ë„ë©”ì¸ ë³´ë„ˆìŠ¤ (ê¸ì •ì  ê°ì„±ì¼ ë•Œ ì¶”ê°€ ê°€ì¤‘ì¹˜)
                if final_sentiment_score > 0.2:
                    base_score *= 1.2
                
                final_score = min(base_score, 1.0)  # 1.0ìœ¼ë¡œ ì œí•œ
                
                # ì¶”ì²œ ì‚¬ìœ  ìƒì„± (ë” ìƒì„¸í•˜ê²Œ)
                matched_keywords = [kw for kw in news_keywords 
                                  if any(stock_kw in kw or kw in stock_kw for stock_kw in stock_info["keywords"])]
                
                reasoning = f"ë§¤ì¹­ í‚¤ì›Œë“œ: {', '.join(matched_keywords[:3])} | "
                reasoning += f"ê°ì„±: {sentiment_result['ì˜ˆì¸¡']}({final_sentiment_score:+.3f}) | "
                reasoning += f"ë§¤ì¹­ë„: {keyword_match_score:.3f} | "
                reasoning += f"ì„¹í„°: {sector}"
                
                # ë¦¬ìŠ¤í¬ ë ˆë²¨ ê²°ì • (í–¥ìƒëœ ë°©ì‹)
                risk_level = self.determine_risk_level(final_sentiment_score, overall_confidence, keyword_match_score)
                
                recommendation = StockRecommendation(
                    symbol=stock_info["symbol"],
                    name=stock_name,
                    sector=sector,
                    sentiment_score=final_sentiment_score,
                    confidence=final_score,
                    reasoning=reasoning,
                    risk_level=risk_level
                )
                
                recommendations.append(recommendation)
        
        # ì‹ ë¢°ë„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ Nê°œ ë°˜í™˜
        recommendations.sort(key=lambda x: x.confidence, reverse=True)
        return recommendations[:top_n]

# === ë¶„ì„ ë° ì¶”ì²œ í†µí•© ì‹œìŠ¤í…œ ===
def analyze_news_and_recommend_stocks(news_text: str, top_n: int = 5):
    """KR-FinBert-SC ê¸°ë°˜ ë‰´ìŠ¤ ë¶„ì„ + ì£¼ì‹ ì¶”ì²œ í†µí•© í•¨ìˆ˜"""
    print("=" * 80)
    print("ğŸ“° KR-FinBert-SC ê¸°ë°˜ ë‰´ìŠ¤ ê°ì„± ë¶„ì„ ë° ì£¼ì‹ ì¶”ì²œ ì‹œìŠ¤í…œ")
    print("=" * 80)
    print(f"ğŸ“° ì…ë ¥ ë‰´ìŠ¤: {news_text}\n")
    
    # 1. ìƒì„¸ ê°ì„± ë¶„ì„
    print("ğŸ“Š ì „ì²´ ë‰´ìŠ¤ ê°ì„± ë¶„ì„:")
    overall_sentiment = predict_sentiment(news_text)
    print(f"ì‚¬ìš© ëª¨ë¸: {overall_sentiment.get('ëª¨ë¸', 'Unknown')}")
    print(f"ì „ì²´ ê°ì„±: {overall_sentiment['ì˜ˆì¸¡']} (ì‹ ë¢°ë„: {overall_sentiment['ì‹ ë¢°ë„']:.4f})")
    print(f"ê°ì„± ì ìˆ˜: {overall_sentiment['ì ìˆ˜']:.4f} (-1: ë§¤ìš°ë¶€ì •, 0: ì¤‘ë¦½, +1: ë§¤ìš°ê¸ì •)")
    
    # ìƒì„¸ í™•ë¥  ì¶œë ¥
    if 'ìƒì„¸í™•ë¥ ' in overall_sentiment:
        probs = overall_sentiment['ìƒì„¸í™•ë¥ ']
        print(f"ìƒì„¸ í™•ë¥ : ë¶€ì •({probs['ë¶€ì •']:.3f}) | ì¤‘ë¦½({probs['ì¤‘ë¦½']:.3f}) | ê¸ì •({probs['ê¸ì •']:.3f})")
    print()
    
    # 2. í‚¤ì›Œë“œ ì¶”ì¶œ
    print("ğŸ”‘ ì¶”ì¶œëœ í‚¤ì›Œë“œ:")
    keywords = extract_keywords(news_text, top_n=12)
    print(", ".join(keywords))
    print()
    
    # 3. ì£¼ì‹ ì¶”ì²œ
    print("ğŸ“ˆ ì£¼ì‹ ì¢…ëª© ì¶”ì²œ:")
    recommender = StockRecommendationEngine()
    recommendations = recommender.recommend_stocks(news_text, top_n)
    
    if not recommendations:
        print("âŒ ê´€ë ¨ ì£¼ì‹ ì¢…ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ìƒìœ„ {len(recommendations)}ê°œ ì¶”ì²œ ì¢…ëª©:")
    print("-" * 100)
    
    for i, rec in enumerate(recommendations, 1):
        print(f"{i}. {rec.name} ({rec.symbol})")
        print(f"   ğŸ“ ì„¹í„°: {rec.sector}")
        print(f"   ğŸ“Š ê°ì„±ì ìˆ˜: {rec.sentiment_score:+.4f}")
        print(f"   ğŸ¯ ì‹ ë¢°ë„: {rec.confidence:.4f}")
        print(f"   âš ï¸  ë¦¬ìŠ¤í¬: {rec.risk_level}")
        print(f"   ğŸ’­ ì¶”ì²œì‚¬ìœ : {rec.reasoning}")
        print("-" * 100)
    
    return recommendations

# === í…ŒìŠ¤íŠ¸ ë° ì‹¤í–‰ ===
def test_stock_recommendation():
    """ë‹¤ì–‘í•œ ë‰´ìŠ¤ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ (KR-FinBert-SC ê¸°ë°˜)"""
    test_cases = [
        {
            "title": "ê¸ì •ì  ê¸°ìˆ  ë‰´ìŠ¤",
            "news": "ì‚¼ì„±ì „ìê°€ ì°¨ì„¸ëŒ€ AI ë°˜ë„ì²´ ê¸°ìˆ  ê°œë°œì— ì„±ê³µí•˜ë©° ê¸€ë¡œë²Œ ë©”ëª¨ë¦¬ ì‹œì¥ì—ì„œì˜ ì§€ë°°ë ¥ì„ ë”ìš± ê°•í™”í–ˆë‹¤. ìƒˆë¡œìš´ ê¸°ìˆ ë¡œ ë°ì´í„°ì„¼í„° ìˆ˜ìš” ê¸‰ì¦ì— ëŒ€ì‘í•  ìˆ˜ ìˆê²Œ ë˜ì–´ ì£¼ê°€ ìƒìŠ¹ì´ ê¸°ëŒ€ëœë‹¤."
        },
        {
            "title": "ë¶€ì •ì  ê¸ˆìœµ ë‰´ìŠ¤", 
            "news": "í•œêµ­ì€í–‰ì˜ ê¸°ì¤€ê¸ˆë¦¬ ì¶”ê°€ ì¸ìƒ ì „ë§ìœ¼ë¡œ ê¸ˆìœµì—…ê³„ ì „ë°˜ì— ë¶€ë‹´ì´ ê°€ì¤‘ë˜ê³  ìˆë‹¤. ëŒ€ì¶œ ìˆ˜ìš” ê°ì†Œì™€ ì¶©ë‹¹ê¸ˆ ì¦ê°€ë¡œ KBê¸ˆìœµ, ì‹ í•œì§€ì£¼ ë“± ì£¼ìš” ì€í–‰ë“¤ì˜ ìˆ˜ìµì„± ì•…í™”ê°€ ìš°ë ¤ëœë‹¤."
        },
        {
            "title": "ê¸ì •ì  ë°”ì´ì˜¤ ë‰´ìŠ¤",
            "news": "ì…€íŠ¸ë¦¬ì˜¨ì˜ ì½”ë¡œë‚˜19 ì¹˜ë£Œì œê°€ FDA ìŠ¹ì¸ì„ ë°›ìœ¼ë©° ê¸€ë¡œë²Œ ì‹œì¥ ì§„ì¶œì˜ ë°œíŒì„ ë§ˆë ¨í–ˆë‹¤. ë°”ì´ì˜¤ì‹œë°€ëŸ¬ í¬íŠ¸í´ë¦¬ì˜¤ í™•ì¥ê³¼ í•¨ê»˜ ë§¤ì¶œ ì¦ëŒ€ê°€ ì˜ˆìƒë˜ì–´ íˆ¬ììë“¤ì˜ ê´€ì‹¬ì´ ì§‘ì¤‘ë˜ê³  ìˆë‹¤."
        },
        {
            "title": "ì „ê¸°ì°¨ ê´€ë ¨ ë‰´ìŠ¤",
            "news": "í˜„ëŒ€ìë™ì°¨ê·¸ë£¹ì´ ì „ê¸°ì°¨ ì „ìš© í”Œë«í¼ E-GMP ê¸°ë°˜ ì‹ ì°¨ ì¶œì‹œë¥¼ ì•ë‘ê³  ìˆìœ¼ë©°, LGí™”í•™ê³¼ì˜ ë°°í„°ë¦¬ ê³µê¸‰ ê³„ì•½ì„ í™•ëŒ€í–ˆë‹¤. ì¹œí™˜ê²½ ëª¨ë¹Œë¦¬í‹° ì‹œì¥ì—ì„œì˜ ê²½ìŸë ¥ ê°•í™”ë¡œ ê´€ë ¨ ì£¼ì‹ë“¤ì˜ ìƒìŠ¹ì´ ê¸°ëŒ€ëœë‹¤."
        },
        {
            "title": "ë¶€ë™ì‚°/ê±´ì„¤ í˜¸ì¬ ë‰´ìŠ¤",
            "news": "ì •ë¶€ì˜ ì£¼íƒê³µê¸‰ í™•ëŒ€ ì •ì±…ê³¼ ì¬ê±´ì¶• ê·œì œ ì™„í™”ë¡œ ê±´ì„¤ì—…ê³„ì— ìƒˆë¡œìš´ ê¸°íšŒê°€ ì—´ë¦¬ê³  ìˆë‹¤. ì‚¼ì„±ë¬¼ì‚°, í˜„ëŒ€ê±´ì„¤ ë“± ëŒ€í˜• ê±´ì„¤ì‚¬ë“¤ì˜ ìˆ˜ì£¼ ì¦ê°€ì™€ ìˆ˜ìµì„± ê°œì„ ì´ ì „ë§ëœë‹¤."
        }
    ]
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nğŸ§ª í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ {i}: {test_case['title']}")
        try:
            recommendations = analyze_news_and_recommend_stocks(test_case['news'], top_n=3)
            
            # ì¶”ê°€ ë¶„ì„ ì •ë³´
            if recommendations:
                avg_sentiment = np.mean([rec.sentiment_score for rec in recommendations])
                print(f"ğŸ“ˆ í‰ê·  ê°ì„± ì ìˆ˜: {avg_sentiment:+.4f}")
                high_confidence = [rec for rec in recommendations if rec.confidence > 0.5]
                print(f"ğŸ¯ ë†’ì€ ì‹ ë¢°ë„ ì¢…ëª© ìˆ˜: {len(high_confidence)}")
            
        except Exception as e:
            print(f"âŒ í…ŒìŠ¤íŠ¸ {i} ì‹¤íŒ¨: {e}")
        
        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        print("\n" + "="*100)

if __name__ == "__main__":
    print("ğŸš€ KR-FinBert-SC ê¸°ë°˜ ê°ì„± ë¶„ì„ ì£¼ì‹ ì¶”ì²œ ì‹œìŠ¤í…œ ì‹œì‘")
    print(f"ğŸ“± ì‚¬ìš© ì¥ì¹˜: {device}")
    print(f"ğŸ¤– ê°ì„± ë¶„ì„ ëª¨ë¸: {sentiment_model_name}")
    test_stock_recommendation()